{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tainatrajano/UCDPA_TainaAraujoTrajano/blob/main/rainfall_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0mZ5-huT1Ps"
      },
      "source": [
        "1. Libraries & Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bie1ddCY762f"
      },
      "outputs": [],
      "source": [
        "from pandas.core.groupby.base import dataclasses\n",
        "###Remove what will not be used\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import requests\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score, KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import roc_curve, classification_report, confusion_matrix, mean_squared_error\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, Ridge\n",
        "\n",
        "#calculates the func of each row and returns on a list #####REVISE\n",
        "def func_by_array(df, list_cols, func):\n",
        "  list_rows = []\n",
        "  i = 0\n",
        "  for i in range(0,len(df.index)):\n",
        "    x = func(df[list_cols].iloc[i].dropna())\n",
        "    list_rows.append(x)\n",
        "\n",
        "  return list_rows\n",
        "\n",
        "#calculates ECDF for a one-dimensional array###REVISE\n",
        "def ecdf(data):\n",
        "    n = len(data)\n",
        "    x = np.sort(data)\n",
        "    y = np.arange(1, n + 1) / n\n",
        "\n",
        "    return x, y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Importing Data"
      ],
      "metadata": {
        "id": "HcEK3cTkgldS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing csv file downloaded from https://www.met.ie/climate/available-data/historical-data website on 30/09/2023\n",
        "dRainfall_df = pd.read_csv(\"/content/drive/MyDrive/database/dublin_rainfall.csv\")\n",
        "kRainfall_df = pd.read_csv(\"/content/drive/MyDrive/database/kerry_rainfall.csv\")\n",
        "\n",
        "#importing data from https://data.gov.ie/dataset/monthly-weather-valentia-observatory to compare data from both sources from 2020-2022 for county Kerry, only mean temperature and rainfall\n",
        "kMonthlyWeather_df = pd.DataFrame()\n",
        "try:\n",
        "  get_API = requests.get('https://prodapi.metweb.ie/monthly-data/Valentia%20Observatory')\n",
        "  kMonthlyWeather_df = pd.DataFrame(get_API.json())\n",
        "\n",
        "except:\n",
        "  print(\"API failed to retrieve data.\")\n"
      ],
      "metadata": {
        "id": "CfxMVME0gkPw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "d7555c3b-ad2c-4d32-dfb0-35ab3c16a208"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-12b38cbda712>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#importing csv file downloaded from https://www.met.ie/climate/available-data/historical-data website on 30/09/2023\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdRainfall_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/database/dublin_rainfall.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mkRainfall_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/database/kerry_rainfall.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#importing data from https://data.gov.ie/dataset/monthly-weather-valentia-observatory to compare data from both sources from 2020-2022 for county Kerry, only mean temperature and rainfall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1776\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 3, saw 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Analysing data"
      ],
      "metadata": {
        "id": "4fz2o9YXBOr-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-eFKJ0ouVsj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01fe6ee7-d450-487a-a36d-537d7c3b18fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 555 entries, 0 to 554\n",
            "Data columns (total 66 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Country Name   555 non-null    object \n",
            " 1   Country Code   555 non-null    object \n",
            " 2   Series Name    555 non-null    object \n",
            " 3   Series Code    555 non-null    object \n",
            " 4   1961 [YR1961]  91 non-null     float64\n",
            " 5   1962 [YR1962]  95 non-null     float64\n",
            " 6   1963 [YR1963]  95 non-null     float64\n",
            " 7   1964 [YR1964]  95 non-null     float64\n",
            " 8   1965 [YR1965]  95 non-null     float64\n",
            " 9   1966 [YR1966]  99 non-null     float64\n",
            " 10  1967 [YR1967]  102 non-null    float64\n",
            " 11  1968 [YR1968]  103 non-null    float64\n",
            " 12  1969 [YR1969]  105 non-null    float64\n",
            " 13  1970 [YR1970]  102 non-null    float64\n",
            " 14  1971 [YR1971]  108 non-null    float64\n",
            " 15  1972 [YR1972]  108 non-null    float64\n",
            " 16  1973 [YR1973]  108 non-null    float64\n",
            " 17  1974 [YR1974]  108 non-null    float64\n",
            " 18  1975 [YR1975]  110 non-null    float64\n",
            " 19  1976 [YR1976]  112 non-null    float64\n",
            " 20  1977 [YR1977]  114 non-null    float64\n",
            " 21  1978 [YR1978]  117 non-null    float64\n",
            " 22  1979 [YR1979]  117 non-null    float64\n",
            " 23  1980 [YR1980]  118 non-null    float64\n",
            " 24  1981 [YR1981]  130 non-null    float64\n",
            " 25  1982 [YR1982]  134 non-null    float64\n",
            " 26  1983 [YR1983]  137 non-null    float64\n",
            " 27  1984 [YR1984]  137 non-null    float64\n",
            " 28  1985 [YR1985]  139 non-null    float64\n",
            " 29  1986 [YR1986]  140 non-null    float64\n",
            " 30  1987 [YR1987]  142 non-null    float64\n",
            " 31  1988 [YR1988]  145 non-null    float64\n",
            " 32  1989 [YR1989]  147 non-null    float64\n",
            " 33  1990 [YR1990]  148 non-null    float64\n",
            " 34  1991 [YR1991]  339 non-null    float64\n",
            " 35  1992 [YR1992]  340 non-null    float64\n",
            " 36  1993 [YR1993]  343 non-null    float64\n",
            " 37  1994 [YR1994]  344 non-null    float64\n",
            " 38  1995 [YR1995]  346 non-null    float64\n",
            " 39  1996 [YR1996]  530 non-null    float64\n",
            " 40  1997 [YR1997]  356 non-null    float64\n",
            " 41  1998 [YR1998]  531 non-null    float64\n",
            " 42  1999 [YR1999]  357 non-null    float64\n",
            " 43  2000 [YR2000]  532 non-null    float64\n",
            " 44  2001 [YR2001]  361 non-null    float64\n",
            " 45  2002 [YR2002]  538 non-null    float64\n",
            " 46  2003 [YR2003]  541 non-null    float64\n",
            " 47  2004 [YR2004]  548 non-null    float64\n",
            " 48  2005 [YR2005]  549 non-null    float64\n",
            " 49  2006 [YR2006]  549 non-null    float64\n",
            " 50  2007 [YR2007]  549 non-null    float64\n",
            " 51  2008 [YR2008]  549 non-null    float64\n",
            " 52  2009 [YR2009]  550 non-null    float64\n",
            " 53  2010 [YR2010]  550 non-null    float64\n",
            " 54  2011 [YR2011]  551 non-null    float64\n",
            " 55  2012 [YR2012]  550 non-null    float64\n",
            " 56  2013 [YR2013]  550 non-null    float64\n",
            " 57  2014 [YR2014]  552 non-null    float64\n",
            " 58  2015 [YR2015]  551 non-null    float64\n",
            " 59  2016 [YR2016]  550 non-null    float64\n",
            " 60  2017 [YR2017]  550 non-null    float64\n",
            " 61  2018 [YR2018]  550 non-null    float64\n",
            " 62  2019 [YR2019]  549 non-null    float64\n",
            " 63  2020 [YR2020]  549 non-null    float64\n",
            " 64  2021 [YR2021]  544 non-null    float64\n",
            " 65  region         555 non-null    object \n",
            "dtypes: float64(61), object(5)\n",
            "memory usage: 286.3+ KB\n",
            "None\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "#using method .join() to left join second DataFrame into the first using columns 'cca3', 'Country Code' as index: df\n",
        "if not dfCountryRegion.empty:\n",
        "  df = wdiDf.join(dfCountryRegion.set_index('cca3'), on='Country Code')\n",
        "\n",
        "  #removimg the \" [YRYYYY]\" part of the columns' names using Regex .sub() method, a for loop used to run through columns' names (iterator) and result append to a list\n",
        "  new_headers = []\n",
        "  for s in df.columns:\n",
        "    new_headers.append(re.sub(r\"\\s.YR\\d{4}.\",\"\",s))\n",
        "\n",
        "  df.columns = new_headers\n",
        "  years_list = new_headers[4:len(df.columns)-1]\n",
        "  countries_list = df['Country Name'].unique()\n",
        "  regions_list = df['region'].unique()\n",
        "  series_list = df['Series Name'].unique()\n",
        "  print(df.info())\n",
        "\n",
        "else:\n",
        "    print(\"DataFrame empty.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#considering the data missing is MAR type, KKNImputer will be used to treat the missing data considering values of the region for that indicator ####REVIEW\n",
        "  #compute the np.mean of each row prior the KKNImputer\n",
        "mean_before = func_by_row(df, years_list, np.mean)\n",
        "  # define imputer\n",
        "imputer = KNNImputer(n_neighbors=6, weights='uniform', metric='nan_euclidean')\n",
        "imputed_df = pd.DataFrame([], columns=df.columns)\n",
        "i = 0\n",
        "df_nomissingvalues = df\n",
        "for series in series_list:\n",
        "  for region in regions_list:\n",
        "    filtered_df = df[(df['Series Name'] == series) & (df['region'] == region)]\n",
        "    numerical_columns = filtered_df[years_list]\n",
        "    # Impute missing values using KNNImputer\n",
        "    imputed_data = imputer.fit_transform(numerical_columns)\n",
        "\n",
        "    # Create a new DataFrame with imputed values\n",
        "    imputed_df[years_list] = pd.DataFrame(imputed_data,years_list)\n",
        "\n",
        "  #compute the np.mean of each row after the KKNImputer\n",
        "mean_after = func_by_row(imputed_df, years_list, np.mean)\n",
        "\n",
        "print(\"mean before: {}\".format(mean_before))\n",
        "print(\"mean after: {}\".format(mean_after))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "JKalEKqD0969",
        "outputId": "3e59b985-d098-41a8-db38-9a625be1ec28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-d665c201336c>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Create a new DataFrame with imputed values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mimputed_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myears_list\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimputed_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myears_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimputed_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myears_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;31m#compute the np.mean of each row after the KKNImputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 )\n\u001b[1;32m    721\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m                 mgr = ndarray_to_mgr(\n\u001b[0m\u001b[1;32m    723\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m                     \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    347\u001b[0m     )\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"array\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (48, 61), indices imply (61, 61)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizations ####REViEW\n",
        "_ = sns.lineplot(mean_before, x = years_list, y = [-50,50], colour=\"red\")\n",
        "_ = sns.lineplot(mean_after, x = years_list, y = [-50,50], colour=\"blue\")\n",
        "_ = plt.xlabel(\"No of Row\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_vNgnOiJDI5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Machine Learning"
      ],
      "metadata": {
        "id": "wVjJkYMtH2hT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_JASQOLvFKT"
      },
      "outputs": [],
      "source": [
        "#using LinearRegression to observed if Okun's Law can be supported by this DataFrame, the higher the GDP the lower the unemployment rate, ####REVIEW\n",
        "  #also to observe if the government effectiviness is negative related to the unemployment rate\n",
        "reg = LinearRegression()\n",
        "for row in df.rows:\n",
        "  row = row[4:]\n",
        "  reg.fit(row,[-1,1])\n",
        "  predictions = reg.predict(row,[-1,1])\n",
        "\n",
        "  # Data Splitting\n",
        "X = df[['feature1', 'feature2']]  # Features\n",
        "y = df['target_column']  # Target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  # Linear Regression Model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "  # Model Evaluation\n",
        "mse = mean_squared_error(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Visualise"
      ],
      "metadata": {
        "id": "jtCQxUzGhLW_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOsmaEb0vdR3"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x=years_list, y='feature2', data=df) ####REVIEW\n",
        "plt.title('World Bank Indicators')\n",
        "plt.xlabel('Years')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1GjTFTQaTSBHuPO_x6zv_BSrG0TvojRE9",
      "authorship_tag": "ABX9TyMoz4gHvjikjvIEjto/hR3t",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}